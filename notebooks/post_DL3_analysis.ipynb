{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe60fa59",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1D spectral analysis and light curve calculation from DL3 (energy-dependent angular cuts)\n",
    "\n",
    "Originally created by Chaitanya Priyadarshi and adapted to work with Gammapy v1.1 and the latest DL3 files produced by lstchain v0.10.\n",
    "\n",
    "This is a combination of Gammapy tutorials for the **1D spectral analysis following the ON-OFF forward-folding method and light curve calculation** for point-like-source observations in wobble mode.\n",
    "\n",
    "Original notebooks can be accessed at:\n",
    "\n",
    " - https://docs.gammapy.org/1.1/tutorials/analysis-1d/spectral_analysis_rad_max.html (from DL3 with energy-dependent angular cuts, the *approach followed in this notebook*)\n",
    " - https://docs.gammapy.org/1.1/tutorials/analysis-1d/spectral_analysis.html (from DL3 with global gammaness and angular cuts)\n",
    " - https://docs.gammapy.org/1.1/tutorials/analysis-time/light_curve.html\n",
    " - https://docs.gammapy.org/1.1/tutorials/analysis-time/light_curve_flare.html\n",
    "\n",
    "\n",
    "It reduces a set of DL3 files (with energy-dependent angular cuts) into an energy-binned dataset, fits a spectral model to this dataset, calculates spectral flux points and computes the light curve.\n",
    "\n",
    "Here it is also described how to write all these objects to files, read them back, inspect and plot the results.\n",
    "\n",
    "-----------\n",
    "## Content\n",
    "\n",
    "### 0. Inspect the DL3 file content\n",
    "### 1. Read the DL3 index files and load the data\n",
    "### 2. Selection filters for the observations\n",
    "### 3. Define Target position and energy ranges for reconstructed events\n",
    "\n",
    "### 4. Define the base Map geometries for creating the SpectrumDataset\n",
    "\n",
    "### 5. Data reduction chain\n",
    "\n",
    "### 6. Generate the Spectrum Dataset for all observations\n",
    "\n",
    "### 7. Some plots with the given Dataset\n",
    "\n",
    "### 8. Write all datasets into OGIP files\n",
    "### 9. Get Pivot energy to fix the reference energy and define the Spectrum Model\n",
    "### 10. Spectral Fitting\n",
    "### 11. Check the Flux points\n",
    "### 12. SED plots\n",
    "### 13. Light curve\n",
    "### 14. Save the SED and LC Flux Points and Model to separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e80c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "import numpy as np\n",
    "from regions import CircleSkyRegion, PointSkyRegion\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1babec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.data import DataStore, EventList\n",
    "from gammapy.datasets import (\n",
    "    Datasets,\n",
    "    FluxPointsDataset,\n",
    "    SpectrumDataset,\n",
    "    SpectrumDatasetOnOff,\n",
    ")\n",
    "from gammapy.estimators import FluxPointsEstimator, LightCurveEstimator, FluxPoints\n",
    "from gammapy.makers import (\n",
    "    ReflectedRegionsBackgroundMaker,\n",
    "    SafeMaskMaker,\n",
    "    SpectrumDatasetMaker,\n",
    "    WobbleRegionsFinder\n",
    ")\n",
    "from gammapy.maps import MapAxis, RegionGeom, WcsGeom, Map\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.modeling.models import (\n",
    "    PowerLawSpectralModel,\n",
    "    LogParabolaSpectralModel,\n",
    "    create_crab_spectral_model,\n",
    "    SkyModel,\n",
    ")\n",
    "from gammapy.visualization import plot_spectrum_datasets_off_regions\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "from astropy.time import Time\n",
    "import astropy.units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ed5a5-101a-4f66-ace9-858e7c1adf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the DL3 files\n",
    "base_dir = Path(\"/fefs/aswg/workspace/analysis-school-2024\")\n",
    "dl3_path = base_dir / \"DL3/Crab_Dec_2023\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c1308b",
   "metadata": {},
   "source": [
    "# 0. Inspect the DL3 file content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c573e-71da-4984-a3c9-cbda09a832f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open one of the DL3 files from the directory\n",
    "filename = dl3_path / \"dl3_LST-1.Run15996.fits\"\n",
    "events = EventList.read(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242c39c3-764e-45de-b7a8-db63e5b815bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the event list (here the first 10 events)\n",
    "events.table[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac3e87-5d07-40e1-9b71-3c5e04ada5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can have a look of the events with\n",
    "events.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d1ab8-a995-44d6-8cd2-42a58887b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can select events based any parameter on the table above, e.g. energy:\n",
    "selected_energy = events.select_energy([500 * u.GeV, 1 * u.TeV])\n",
    "selected_energy.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b1cee-bfb6-4e7e-8f9d-cf1effb7f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or gammaness:\n",
    "gh_range = [0.9, 1]\n",
    "selected_events_gh = events.select_parameter(parameter=\"GAMMANESS\", band=gh_range)\n",
    "selected_events_gh.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc4490a-23bd-45ad-81cc-8a8f9430bedb",
   "metadata": {},
   "source": [
    "# 1. Read the DL3 index files and load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658cbcf5",
   "metadata": {},
   "source": [
    "Let's load now all the DL3 files together.\n",
    "If the DL3 index files are not present, run the `lstchain_create_dl3_index_files` for the given DL3 files.\n",
    "\n",
    "`lstchain_create_dl3_index_files -d $dl3_path`  (by default create the index files in the same directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc4bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_datastore = DataStore.from_dir(dl3_path)\n",
    "\n",
    "ogip_path = dl3_path / \"OGIP\"\n",
    "\n",
    "# Create the Paths if they do not exist already\n",
    "ogip_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b54009-d0cd-4c06-a68b-98ebdaa9b6ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's have a first look at the first 5 entries of the table from all observations present in the index files. \n",
    "# It contains run-wise information.\n",
    "total_datastore.obs_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb7717-2e04-475b-92b3-ef83d419b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_datastore.obs_table['LIVETIME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa584be6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Also you can have a look at the HDU table, which contains information on the data \n",
    "# and instrument response function files for each observation\n",
    "total_datastore.hdu_table[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f683b5ad",
   "metadata": {},
   "source": [
    "# 2. Selection filters for the observations\n",
    "\n",
    "Based on the run-wise information from the previous table, filters can be applied to select just a subset of the observation list based on source name, zenith angle or livetime.\n",
    "\n",
    "This list of observations based on similar filters can be also obtained beforehand by using the [data quality notebook](https://github.com/cta-observatory/cta-lstchain/blob/main/notebooks/data_quality.ipynb) (recommended). Then you can directly pass this list of `obs_id` to `get_observations` method of `DataStore` object below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40149928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the object name from the OBS Table, assuming all the DL3 files are of the same single source.\n",
    "# If not, then select a single object, to produce the relevant Spectrum Dataset\n",
    "\n",
    "obj_name = np.unique(total_datastore.obs_table[\"OBJECT\"])[0]\n",
    "print(\"The source is\", obj_name)\n",
    "\n",
    "max_zen = 60  # in deg for a maximum limit on zenith pointing of observations\n",
    "min_time = 0  # in seconds for minimum livetime of each observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2527c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_obs_list = total_datastore.obs_table[\"OBS_ID\"].data\n",
    "observations_total = total_datastore.get_observations(\n",
    "    total_obs_list, \n",
    "    required_irf=[\"aeff\", \"edisp\", \"rad_max\"],  # By default, \"full-enclosure\" : [\"events\", \"gti\", \"aeff\", \"edisp\", \"psf\", \"bkg\"]\n",
    "                        # If not all IRFs are present, the entry will be skipped \n",
    "    skip_missing=False # Skip missing observations, within the list provided earlier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f8226c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_time = total_datastore.obs_table[\"LIVETIME\"] > min_time\n",
    "d_zen = total_datastore.obs_table[\"ZEN_PNT\"] < max_zen\n",
    "d_obj = total_datastore.obs_table[\"OBJECT\"] == obj_name\n",
    "\n",
    "obs_table_selected = total_datastore.obs_table[d_zen & d_obj & d_time]\n",
    "obs_id_list = obs_table_selected[\"OBS_ID\"]\n",
    "\n",
    "observations_sel = total_datastore.get_observations(\n",
    "    obs_id_list, \n",
    "    required_irf=\"point-like\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d39c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Observation runs selected are:', obs_id_list.data)\n",
    "print(f'Total livetime of all observations: {total_datastore.obs_table[\"LIVETIME\"].to(u.h).sum():.1f}')\n",
    "print(f'Total livetime of selected observations {obs_table_selected[\"LIVETIME\"].data.sum()/3600:.1f} hrs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4220a9",
   "metadata": {},
   "source": [
    "# 3. Define Target position and energy ranges for reconstructed events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa0999",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_position = SkyCoord.from_name(\"Crab\", frame='icrs')\n",
    "target_position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d00c086-8be2-4815-a450-a4054d5fa41f",
   "metadata": {},
   "source": [
    "If we were using global theta cut, this is the way of getting the theta cut (`RAD_MAX` key) used for the IRF production.\n",
    "\n",
    "Here we will use energy-dependent cuts, therefore the following is not executed in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc29858-9b8e-49f1-9e7a-daffe127091f",
   "metadata": {},
   "source": [
    "```\n",
    "# Find the fixed global theta cut used for creating the IRFs\n",
    "\n",
    "theta_cut = observations_sel[0].aeff.meta[\"RAD_MAX\"]\n",
    "print(\"Theta cut applied for creating the IRF in the selected DL3 file,\", theta_cut)\n",
    "\n",
    "# Converting the value into astropy.units to be used for defining the ON region with CircleSkyRegion\n",
    "on_region_radius = u.Quantity(theta_cut)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0afac4-476b-4708-b9ef-8b19f807c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The metadata of the DL3 contains the efficiency of the cuts used for the DL3 production.\n",
    "observations_sel[0].aeff.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f9d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the minimum, maximum energies in TeV units, and number of bins per decade, to create the \n",
    "# required reconstructed and true energy ranges.\n",
    "# For Light Curve estimation and spectral fitting, flux calculation can be only performed within \n",
    "# the energy edges provided for the reconstructed events.\n",
    "# For example, if the reconstructed energy edges are [0.01, 0.1, 1, 10] TeV and you want LC in \n",
    "# [0.05, 10] TeV energy range, then, reproduce the Dataset objects with those reconstructed energy edges.\n",
    "\n",
    "e_reco_min = 0.05 # 0.01\n",
    "e_reco_max = 50\n",
    "\n",
    "e_true_min = 0.01\n",
    "e_true_max = 100\n",
    "\n",
    "# Using bins per decade\n",
    "e_reco_bin_p_dec = 8\n",
    "e_true_bin_p_dec = 10\n",
    "\n",
    "energy_axis = MapAxis.from_energy_bounds(\n",
    "    e_reco_min, e_reco_max, \n",
    "    nbin=e_reco_bin_p_dec, per_decade=True, \n",
    "    unit=\"TeV\", name=\"energy\"\n",
    ")\n",
    "energy_axis_true = MapAxis.from_energy_bounds(\n",
    "    e_true_min, e_true_max, \n",
    "    nbin=e_true_bin_p_dec, per_decade=True, \n",
    "    unit=\"TeV\", name=\"energy_true\"\n",
    ")\n",
    "\n",
    "# Select minimum and maximum energy edges for the SED, from the energy_axis to be used un the Dataset\n",
    "# Here we use a different minimum energy than energy_axis, but the same energy bins.\n",
    "# For analyzers who do not want energy bins per decade, or some custom bins for energy_axis, \n",
    "# make appropriate changes in each axis.\n",
    "e_fit_min = energy_axis.edges[1].value\n",
    "e_fit_max = energy_axis.edges[-1].value\n",
    "e_fit_bin_p_dec = e_reco_bin_p_dec\n",
    "\n",
    "# Just to have a separate MapAxis for spectral fit energy range\n",
    "energy_fit_edges = MapAxis.from_energy_bounds(\n",
    "    e_fit_min, e_fit_max, \n",
    "    nbin=e_fit_bin_p_dec, per_decade=True, \n",
    "    unit=\"TeV\"\n",
    ").edges\n",
    "\n",
    "\n",
    "print(\"Spectral Fit will be done in energy edges:\\n\", energy_fit_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f4149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can access the energy edges and center values\n",
    "energy_axis_true.edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecb339f",
   "metadata": {},
   "source": [
    "# 4. Define the base Map geometries for creating the SpectrumDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac5aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_region = PointSkyRegion(target_position)  \n",
    "\n",
    "# This will create the base geometry in which to bin the events based on their reconstructed positions\n",
    "on_geom = RegionGeom.create(\n",
    "    on_region, \n",
    "    axes=[energy_axis]\n",
    ")\n",
    "# In case of using global angular cut `CircleSkyRegion` should be used instead (see \"Spectral analysis Gammapy tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06651bb8",
   "metadata": {},
   "source": [
    "# 5. Data Reduction chain\n",
    "Create some Dataset and Data Reduction Makers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b8885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geom is the target geometry in reco energy for counts and background maps\n",
    "# energy_axis_true is the true energy axis for the IRF maps\n",
    "dataset_empty = SpectrumDataset.create(\n",
    "    geom=on_geom, \n",
    "    energy_axis_true=energy_axis_true\n",
    ")\n",
    "# When not including a PSF IRF, put the containment_correction as False\n",
    "dataset_maker = SpectrumDatasetMaker(\n",
    "    containment_correction=False, \n",
    "    selection=[\"counts\", \"exposure\", \"edisp\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b14ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following makers can be tuned and played to check the final Dataset to be used.\n",
    "\n",
    "# In the case of energy-dependent angular cuts we have to use the `WobbleRegionsFinder`, \n",
    "# to determine the OFF positions, depending on the number of regions specified.\n",
    "# Their sizes will be defined by the theta values in RAD_MAX_2D table based on the estimated energy binning.\n",
    "# The same logic applies to the size of the ON region.\n",
    "\n",
    "\n",
    "# Background maker will use the WobbleRegionsFinder, assuming 1 OFF region for the background estimation\n",
    "region_finder = WobbleRegionsFinder(n_off_regions=1)\n",
    "bkg_maker = ReflectedRegionsBackgroundMaker(region_finder=region_finder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7778cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maker for safe energy range for the events.\n",
    "safe_mask_maker = SafeMaskMaker(\n",
    "    methods=[\"aeff-max\"], \n",
    "    aeff_percent=5\n",
    ")\n",
    "\n",
    "# Or make a custom safe energy range for the events.\n",
    "#safe_min_energy = 50 * u.GeV\n",
    "#safe_max_energy = 20 * u.TeV\n",
    "# For other arguments and options, check the documentation,\n",
    "# https://docs.gammapy.org/1.1/api/gammapy.makers.SafeMaskMaker.html#gammapy.makers.SafeMaskMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c37d609",
   "metadata": {},
   "source": [
    "# 6. Generate the Spectrum Dataset for all observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b17e0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# The final object will be stored as a Datasets object\n",
    "\n",
    "# There will be an error message on use_region_center=False. It is a bug message in gammapy, so just ignore it\n",
    "datasets = Datasets()\n",
    "\n",
    "# Create a counts map for visualisation later\n",
    "counts = Map.create(skydir=target_position, width=3)\n",
    "\n",
    "for obs_id, observation in zip(obs_id_list, observations_sel):\n",
    "    dataset = dataset_maker.run(\n",
    "        dataset_empty.copy(name=str(obs_id)), \n",
    "        observation\n",
    "    )\n",
    "    print('obs_id:', obs_id)\n",
    "    dataset_on_off = bkg_maker.run(\n",
    "        dataset=dataset, \n",
    "        observation=observation\n",
    "    )\n",
    "    counts.fill_events(observation.events)\n",
    "    \n",
    "    # Check the LC and SEDs by applying the safe mask to see the distinction.\n",
    "    dataset_on_off = safe_mask_maker.run(dataset_on_off, observation)\n",
    "    \n",
    "    # Or use custom safe energy range\n",
    "    #dataset_on_off.mask_safe = dataset_on_off.counts.geom.energy_mask(\n",
    "    #    energy_min=safe_min_energy, energy_max=safe_max_energy\n",
    "    #)\n",
    "    \n",
    "    datasets.append(dataset_on_off)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b75eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datasets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea40a2a",
   "metadata": {},
   "source": [
    "# 7. Some plots with the given Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1022d2-516b-4454-858f-3de4848f9591",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaea147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the target position and OFF regions used for the calculation of the excess\n",
    "ax = counts.plot(cmap=\"viridis\", stretch=\"sinh\")\n",
    "on_geom.plot_region(ax=ax, kwargs_point={\"color\": \"k\", \"marker\": \"*\"})\n",
    "plot_spectrum_datasets_off_regions(ax=ax, datasets=datasets)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3bf4ab3f",
   "metadata": {},
   "source": [
    "# For source dependent analysis, check the reconstructed position of all the events, \n",
    "# to be sure on the type of dateset we have\n",
    "for o in observations_wob:\n",
    "    table=o.events.table\n",
    "    plt.plot((table[\"RA\"]*24/360),(table[\"DEC\"]), '.')\n",
    "plt.grid()\n",
    "plt.gca().invert_xaxis()\n",
    "plt.xlabel(\"RA (deg)\")\n",
    "plt.ylabel(\"Dec (deg)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bac0518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "info_table = datasets.info_table(cumulative=True)\n",
    "info_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899bc210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temporal evolution of excess events and significance value\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(\n",
    "    info_table[\"livetime\"].to(\"h\"), info_table[\"excess\"], marker=\"o\", ls=\"none\"\n",
    ")\n",
    "plt.plot(info_table[\"livetime\"].to(\"h\")[-1:1], info_table[\"excess\"][-1:1], 'r')\n",
    "plt.xlabel(\"Livetime (h)\")\n",
    "plt.ylabel(\"Excess\")\n",
    "plt.grid()\n",
    "plt.title('Excess vs Livetime')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(\n",
    "    np.sqrt(info_table[\"livetime\"].to(\"h\")),\n",
    "    info_table[\"sqrt_ts\"],\n",
    "    marker=\"o\",\n",
    "    ls=\"none\",\n",
    ")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Sqrt Livetime h^(1/2)\")\n",
    "plt.ylabel(\"sqrt_ts\")\n",
    "plt.title('Significance vs Square root of Livetime')\n",
    "plt.subplots_adjust(wspace=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9fdb9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Plot the counts+excess, exposure and energy migration of each selected dataset\n",
    "for data in datasets:\n",
    "    plt.figure(figsize=(21, 5.5))\n",
    "    plt.subplot(131)\n",
    "    data.plot_counts()\n",
    "    data.plot_excess()\n",
    "    plt.grid(which=\"both\")\n",
    "    plt.title(f'Run {data.name} Counts and Excess')\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    data.exposure.plot()\n",
    "    plt.grid(which='both')\n",
    "    plt.title(f'Run {data.name} Exposure')\n",
    "    \n",
    "    plt.subplot(133)\n",
    "    if data.edisp is not None:\n",
    "        kernel = data.edisp.get_edisp_kernel()\n",
    "        kernel.plot_matrix(add_cbar=True)\n",
    "        plt.title(f'Run {data.name} Energy Dispersion')\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5f672",
   "metadata": {},
   "source": [
    "# 8. Write all datasets into OGIP files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1177b138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d in datasets:\n",
    "    d.write(\n",
    "        filename=ogip_path / f\"obs_{d.name}.fits.gz\", overwrite=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa00c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the OGIP files to include the source object name in its headers, to be used for further analysis\n",
    "for obs in obs_id_list:\n",
    "    file = ogip_path/f\"obs_{obs}.fits.gz\"\n",
    "    \n",
    "    d1 = fits.open(file)\n",
    "    d1.writeto(file, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57330fc9",
   "metadata": {},
   "source": [
    "# 9. Get Pivot energy to fix the reference energy and define the Spectrum Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find pivot (decorrelation) energy for a Power Law model to get the reference energy for Log Parabola model\n",
    "def get_pivot_energy(datasets, e_ref, e_edges, obj_name):\n",
    "    \"\"\"\n",
    "    Using Power Law spectral model with the given reference energy and \n",
    "    get the decorrelation energy of the fit, within the fit energy range, e_edges.\n",
    "    This method is further explained in doi:10.1088/0004-637X/707/2/1310\n",
    "    \"\"\"\n",
    "    spectral_model = PowerLawSpectralModel(\n",
    "        index=2, amplitude=2e-11 * u.Unit(\"cm-2 s-1 TeV-1\"), reference=e_ref\n",
    "    )\n",
    "    model = SkyModel(spectral_model=spectral_model, name=obj_name)\n",
    "    model_check = model.copy()\n",
    "\n",
    "    # Stacked dataset method\n",
    "    stacked_dataset = Datasets(datasets).stack_reduce()\n",
    "    stacked_dataset.models = model_check\n",
    "\n",
    "    fit_stacked = Fit()\n",
    "    result_stacked = fit_stacked.run(datasets=stacked_dataset)\n",
    "\n",
    "    return model_check.spectral_model.pivot_energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a8072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a reference energy close to the expected decorrelation energy\n",
    "ref = get_pivot_energy(datasets, 0.4 * u.TeV, energy_axis.edges, obj_name)\n",
    "print(ref.to_value(u.GeV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea893639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final spectral model of Log Parabola, to be used for estimating the LC.\n",
    "# One can try different Spectral Models as well.\n",
    "# Be careful in the choice of Spectral Model being used for the 2 examples presented here\n",
    "\n",
    "# Crab\n",
    "spectral_model_lp = LogParabolaSpectralModel(\n",
    "        amplitude = 5e-12 * u.Unit('cm-2 s-1 TeV-1'),\n",
    "        reference = ref,\n",
    "        alpha = 2 * u.Unit(''),\n",
    "        beta = 0.1 * u.Unit('')\n",
    ")\n",
    "model_lp = SkyModel(spectral_model=spectral_model_lp, name=obj_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the appropriate models, as per the selection of the source/dataset\n",
    "params=model_lp.to_dict()['spectral']\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f4de45",
   "metadata": {},
   "source": [
    "# 10. Spectral Fitting\n",
    "One can check for a more comprehensive tutorial on Modelling and Fitting in the Gammapy tutorials\n",
    "* https://docs.gammapy.org/1.1/tutorials/api/fitting.html\n",
    "* https://docs.gammapy.org/1.1/tutorials/api/model_management.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f74af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using stacked analysis method, where we stack together all Datasets into 1 Dataset and add the model afterwards\n",
    "stacked_dataset = Datasets(datasets).stack_reduce()\n",
    "stacked_dataset.models = model_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca480c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model to the dataset\n",
    "fit = Fit()\n",
    "result = fit.run(datasets=stacked_dataset)\n",
    "model_best = model_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aa71d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best.parameters[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bc612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Flux Points after Fitting the model\n",
    "# We do not do too many optimizations here. \n",
    "# If one wants, can try and check the various attributes of the Estimator\n",
    "fpe = FluxPointsEstimator(\n",
    "    energy_edges=energy_fit_edges, \n",
    "    reoptimize = False, # Re-optimizing other free model parameters (not belonging to the source)\n",
    "    source=obj_name,\n",
    "    selection_optional=\"all\" # Estimates asymmetric errors, upper limits and fit statistic profiles\n",
    ")\n",
    "flux_points = fpe.run(datasets=stacked_dataset)\n",
    "\n",
    "flux_points_dataset = FluxPointsDataset(\n",
    "    data=flux_points, models=model_best\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b85bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08292402",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best.to_dict()['spectral']['parameters']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2a5fa1",
   "metadata": {},
   "source": [
    "# 11. Check the Flux points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201138aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Flux table\n",
    "# sed_type options are {“likelihood”, “dnde”, “e2dnde”, “flux”, “eflux”} with \"likelihood\" being default\n",
    "# format options are {“gadf-sed”, “lightcurve”, “binned-time-series”, “profile”} with \"gadf-sed\" being default\n",
    "flux_points.to_table(formatted=True, sed_type=\"e2dnde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc6eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Statistic array\n",
    "print(flux_points_dataset.stat_array())\n",
    "\n",
    "# Total statistics sum\n",
    "print(flux_points_dataset.stat_sum(), np.nansum(flux_points_dataset.stat_array()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5715f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Fit results to the model object to save it to file\n",
    "model_final = model_best.to_dict()\n",
    "model_final[\"FitResult\"] = {\n",
    "    \"Optimize\": result.optimize_result,\n",
    "    \"Covariance\": result.covariance_result\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdffeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best.parameters.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8fc62f",
   "metadata": {},
   "source": [
    "# 12. SED Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e147ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_label=\"Crab MAGIC LP (JHEAp 2015)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcbeb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_points.to_table(formatted=True, sed_type=\"e2dnde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0972b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting plot axes limits and other args\n",
    "\n",
    "# Here we plot only in the energy range from where we have the first flux point, and before the first UL.\n",
    "# This is based on the selection we used earlier on the dataset and the Flux points estimation we get.\n",
    "# One should adjust the limit as per selections used earlier.\n",
    "\n",
    "positive_flux = flux_points.to_table(formatted=True, sed_type=\"e2dnde\")[\"e2dnde\"] > 0\n",
    "e_plot_min = flux_points.to_table(formatted=True, sed_type=\"e2dnde\")[\"e_min\"].quantity[positive_flux][0]\n",
    "\n",
    "non_ul = flux_points.to_table(formatted=True, sed_type=\"e2dnde\")[\"is_ul\"] == 0\n",
    "e_plot_max = flux_points.to_table(formatted=True, sed_type=\"e2dnde\")[\"e_max\"].quantity[non_ul][-1]\n",
    "\n",
    "sed_kwargs = {\n",
    "    \"sed_type\": \"e2dnde\",\n",
    "    \"energy_bounds\": [e_plot_min, e_plot_max],\n",
    "}\n",
    "\n",
    "# Using the energy range used in the MAGIC reference\n",
    "ds_magic_ref_kwargs = {\n",
    "    \"sed_type\": \"dnde\",\n",
    "    \"energy_bounds\": [50 * u.GeV, 30 * u.TeV],\n",
    "}\n",
    "sed_magic_ref_kwargs = {\n",
    "    \"sed_type\": \"e2dnde\",\n",
    "    \"energy_bounds\": [50 * u.GeV, 30 * u.TeV],\n",
    "}\n",
    "sed_plot_kwargs = {\n",
    "    \"label\": \"LST-1 data\",\n",
    "}\n",
    "plot_ts_kwargs = {\n",
    "    \"color\": \"darkorange\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c738513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & plot Crab reference flux\n",
    "# https://doi.org/10.1016/j.jheap.2015.01.002\n",
    "crab = create_crab_spectral_model(\"magic_lp\")\n",
    "crab.amplitude.error = 0.03e-11 * u.Unit(\"cm-2 s-1 TeV-1\")\n",
    "crab.alpha.error = 0.01\n",
    "crab.beta.error = 0.01/np.log(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce6ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "ax = flux_points.plot(sed_type=\"e2dnde\", **plot_ts_kwargs)\n",
    "\n",
    "flux_points.plot_ts_profiles(ax=ax, sed_type=\"e2dnde\")\n",
    "plt.xlim(e_plot_min.value, e_plot_max.value)\n",
    "\n",
    "plt.grid(which='both')\n",
    "plt.title('TS Profiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b780856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model covariance matrix plot\n",
    "model_best.covariance.plot_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf9a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_sed = plt.figure(figsize=(8,8))\n",
    "\n",
    "gs2 = GridSpec(7, 1)\n",
    "\n",
    "gs2.update(hspace=0.1)\n",
    "args1 = [gs2[:5,:]]\n",
    "args2 = [gs2[5:,:]]\n",
    "\n",
    "fig_gs1 = fig_sed.add_subplot(*args1)\n",
    "fig_gs2 = fig_sed.add_subplot(*args2)\n",
    "\n",
    "FluxPointsDataset(data=flux_points, models=model_best).plot_spectrum(\n",
    "    ax=fig_gs1, \n",
    "    kwargs_fp=sed_plot_kwargs, \n",
    ")\n",
    "\n",
    "create_crab_spectral_model(\"magic_lp\").plot(\n",
    "    ax=fig_gs1, **sed_magic_ref_kwargs, label=ref_label\n",
    ")\n",
    "\n",
    "fig_gs1.legend()\n",
    "fig_gs1.set_xlim(e_plot_min.value, e_plot_max.value)\n",
    "fig_gs1.set_ylim(2e-12, 2e-10)\n",
    "fig_gs1.tick_params(labelbottom=False)\n",
    "\n",
    "fig_gs1.grid(which='both')\n",
    "fig_gs1.set_title('SED')\n",
    "\n",
    "flux_points_dataset.plot_residuals(ax=fig_gs2, method='diff/model')\n",
    "fig_gs2.grid(which='both')\n",
    "fig_gs2.set_xlim(e_plot_min.value, e_plot_max.value);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,7))\n",
    "gs = GridSpec(7, 1)\n",
    "\n",
    "args1 = [gs[:5,:]]\n",
    "args2 = [gs[5:,:]]\n",
    "kwargs_res = {\"method\": \"diff/sqrt(model)\"}\n",
    "\n",
    "fig_gs1 = fig.add_subplot(*args1)\n",
    "fig_gs2 = fig.add_subplot(*args2)\n",
    "\n",
    "stacked_dataset.plot_excess(fig_gs1)\n",
    "fig_gs1.grid(which=\"both\")\n",
    "fig_gs1.set_ylabel(\"Excess\")\n",
    "\n",
    "stacked_dataset.plot_residuals_spectral(fig_gs2, **kwargs_res, region=stacked_dataset.counts.geom.region)\n",
    "fig_gs2.grid(which=\"both\")\n",
    "\n",
    "fig_gs2.set_ylabel(f\"Residuals \\n (data-model)/sqrt(model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7acd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "flux_points.plot(sed_type=\"dnde\", label='Joint flux')\n",
    "create_crab_spectral_model(\"magic_lp\").plot(**ds_magic_ref_kwargs, label=ref_label)\n",
    "plt.xlim(e_plot_min.value, e_plot_max.value)\n",
    "plt.grid(which='both')\n",
    "plt.legend()\n",
    "plt.title('Differential spectrum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a699cc1",
   "metadata": {},
   "source": [
    "# 13. Light curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984355b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define energy range for the light curve. It has to match the edges of the \n",
    "# reconstructed energy binning set for the SED! :\n",
    "e_lc_min = energy_axis.edges[5]\n",
    "e_lc_max = energy_axis.edges[-1]\n",
    "print(\"LC will be estimated from \", e_lc_min, \"to \", e_lc_max)\n",
    "\n",
    "# Plotting settings\n",
    "lc_kwargs = {\n",
    "    \"marker\": \"o\", \n",
    "    \"label\": \"LST-1\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea17f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the GTI parameters of each observation to create time intervals for plotting LC\n",
    "t_start = []\n",
    "t_stop = []\n",
    "tot_time = []\n",
    "\n",
    "for obs in observations_sel:\n",
    "    gti = obs.gti\n",
    "    \n",
    "    t_start.append(gti.time_start[0])\n",
    "    t_stop.append(gti.time_stop[0])\n",
    "    tot_time.append(gti.time_sum.value)\n",
    "\n",
    "t_start = np.sort(np.array(t_start))\n",
    "t_stop = np.sort(np.array(t_stop))\n",
    "tot_time = np.array(tot_time)\n",
    "\n",
    "t_start = Time(t_start)\n",
    "t_stop = Time(t_stop)\n",
    "\n",
    "t_day = np.unique(np.rint(t_start.mjd))\n",
    "\n",
    "# To make the range night-wise, keep the MJD range in half-integral values\n",
    "t_range = [Time([t-0.5, t+0.5], format=\"mjd\", scale=\"utc\") for t in t_day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f52eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LC Estimator on a run-by-run basis and nightly\n",
    "lc_maker_1d = LightCurveEstimator(\n",
    "    energy_edges=[e_lc_min, e_lc_max], \n",
    "    reoptimize=False, # Re-optimizing other free model parameters (not belonging to the source)\n",
    "    source=obj_name, \n",
    "    selection_optional=\"all\" # Estimates asymmetric errors, upper limits and fit statistic profiles\n",
    ")\n",
    "\n",
    "lc_maker_night_wise = LightCurveEstimator(\n",
    "    energy_edges=[e_lc_min, e_lc_max], \n",
    "    time_intervals=t_range,\n",
    "    reoptimize=False, \n",
    "    source=obj_name,\n",
    "    selection_optional=\"all\"\n",
    ")\n",
    "\n",
    "# Assigning the best fit model for each dataset\n",
    "for data in datasets:\n",
    "    data.models = model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d128752",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_1d = lc_maker_1d.run(datasets)\n",
    "lc_night = lc_maker_night_wise.run(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433dc50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are more than 1 night of data, one can see the integrated light curve for each night\n",
    "lc_night.to_table(sed_type=\"flux\", format=\"lightcurve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c4493c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the various column data of the Light Curve object\n",
    "lc_1d.to_table(sed_type=\"flux\", format=\"lightcurve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab744d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Crab reference flux\n",
    "flux_crab, flux_crab_error = crab.integral_error(e_lc_min, e_lc_max)\n",
    "print(flux_crab, flux_crab_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dc5b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lc = plt.figure(figsize=(8,10))\n",
    "\n",
    "gs2 = GridSpec(10, 5)\n",
    "\n",
    "gs2.update(wspace=0.4)\n",
    "args1 = [gs2[:5,:]]\n",
    "args2 = [gs2[5:,:]]\n",
    "\n",
    "fig_gs1 = fig_lc.add_subplot(*args1)\n",
    "fig_gs2 = fig_lc.add_subplot(*args2, sharey=fig_gs1)\n",
    "\n",
    "lc_1d.plot(\n",
    "    ax=fig_gs1,\n",
    "    sed_type=\"flux\",\n",
    "    **lc_kwargs\n",
    ")\n",
    "fig_gs1.axhline(\n",
    "    flux_crab.to_value(\"cm-2 s-1\"), c='red', ls='--', \n",
    "    label='Crab (MAGIC, JHEAp 2015)'\n",
    ")\n",
    "fig_gs1.axhspan(\n",
    "    (flux_crab - flux_crab_error).to_value(\"cm-2 s-1\"), \n",
    "    (flux_crab + flux_crab_error).to_value(\"cm-2 s-1\"), \n",
    "    alpha=0.2, color='tab:orange'\n",
    ")\n",
    "fig_gs1.get_xaxis().set_ticklabels([])\n",
    "fig_gs1.grid(which='both')\n",
    "fig_gs1.set_title(\n",
    "    f'LC LST-1 {obj_name}: {e_lc_min.to(u.GeV):.0f} < E < {e_lc_max.to(u.TeV):.1f} \\nRun-wise {tot_time.sum()/3600:.1f} hrs, night-wise {len(t_day)} nights'\n",
    ")\n",
    "fig_gs1.legend()\n",
    "fig_gs2.set_yscale('linear')\n",
    "\n",
    "# Custom y-axis range, if needed:\n",
    "#fig_gs2.set_ylim(0, 4e-10)\n",
    "#fig_gs2.set_ylim(0, 5e-11)\n",
    "\n",
    "fig_gs2.set_ylim(0, 1.5*np.nanmax(lc_1d.flux.data))\n",
    "\n",
    "fig_gs1.get_yaxis().get_offset_text().set_position((-0.06,1))\n",
    "\n",
    "lc_night.plot(\n",
    "    ax=fig_gs2,\n",
    "    sed_type=\"flux\",\n",
    "    axis_name=\"time\",\n",
    "    **lc_kwargs\n",
    ")\n",
    "fig_gs2.axhline(\n",
    "    flux_crab.to_value(\"cm-2 s-1\"), c='red', ls='--', \n",
    "    label='Crab (MAGIC, JHEAp 2015)'\n",
    ")\n",
    "fig_gs2.axhspan(\n",
    "    (flux_crab - flux_crab_error).to_value(\"cm-2 s-1\"), \n",
    "    (flux_crab + flux_crab_error).to_value(\"cm-2 s-1\"), \n",
    "    alpha=0.2, color='tab:orange'\n",
    ")\n",
    "\n",
    "fig_gs2.grid(which='both')\n",
    "fig_gs2.set_yscale('linear')\n",
    "fig_gs2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d440e05",
   "metadata": {},
   "source": [
    "# 14. Save the SED and LC Flux Points and Model to separate files\n",
    "## This way, one can plot different SEDs and LCs together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the model and Optimization results into a file\n",
    "f = open(dl3_path / f'{obj_name}_dataset_{datasets[0].name}_to_{datasets[-1].name}_flux_model_dict.dat', 'wb')\n",
    "pickle.dump(model_final, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10146e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary fits file with the SED and LC Flux Points tables\n",
    "f = fits.HDUList(\n",
    "    [\n",
    "        fits.PrimaryHDU(),\n",
    "        fits.BinTableHDU(flux_points.to_table(), name=\"SED\"),\n",
    "        fits.BinTableHDU(lc_1d.to_table(sed_type=\"flux\", format=\"lightcurve\"), name=\"LC\"),\n",
    "    ]\n",
    ")\n",
    "f.writeto(\n",
    "    dl3_path / f'{obj_name}_dataset_{datasets[0].name}_to_{datasets[-1].name}_flux_pts.fits', \n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4a5607",
   "metadata": {},
   "source": [
    "### Example on reading back and plotting the LC and SED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df1b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_model = open(\n",
    "    dl3_path / f'{obj_name}_dataset_{datasets[0].name}_to_{datasets[-1].name}_flux_model_dict.dat', \n",
    "    'rb'\n",
    ")\n",
    "model_dict = pickle.load(flux_model)\n",
    "flux_model.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94240408",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_points = FluxPoints.read(\n",
    "    dl3_path / f'{obj_name}_dataset_{datasets[0].name}_to_{datasets[-1].name}_flux_pts.fits',\n",
    "    hdu=\"SED\",\n",
    "    format=\"gadf-sed\",\n",
    "    reference_model=SkyModel.from_dict(model_dict)\n",
    ")\n",
    "flux_points_lc = FluxPoints.read(\n",
    "    dl3_path / f'{obj_name}_dataset_{datasets[0].name}_to_{datasets[-1].name}_flux_pts.fits',\n",
    "    hdu=\"LC\",\n",
    "    sed_type=\"flux\", \n",
    "    format=\"lightcurve\",\n",
    "    reference_model=SkyModel.from_dict(model_dict)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "flux_points_lc.plot(sed_type=\"flux\", **lc_kwargs)\n",
    "plt.grid(which=\"both\")\n",
    "plt.title(\n",
    "    f'LC {flux_points_lc.to_table(sed_type=\"flux\", format=\"lightcurve\")[\"e_min\"].quantity[0][0].to(u.GeV):.2f} < ' +\n",
    "    f'E < {flux_points_lc.to_table(sed_type=\"flux\", format=\"lightcurve\")[\"e_max\"].quantity[0][0]:.2f}'\n",
    ")\n",
    "plt.axhline(\n",
    "    flux_crab.to_value(\"cm-2 s-1\"), c='red', ls='--', label=ref_label\n",
    ")\n",
    "plt.axhspan(\n",
    "    (flux_crab - flux_crab_error).to_value(\"cm-2 s-1\"), \n",
    "    (flux_crab + flux_crab_error).to_value(\"cm-2 s-1\"), \n",
    "    alpha=0.2, color='tab:orange'\n",
    ")\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "flux_points.plot(sed_type=\"e2dnde\", **sed_plot_kwargs)\n",
    "flux_points.reference_model.spectral_model.plot(**sed_kwargs)\n",
    "flux_points.reference_model.spectral_model.plot_error(**sed_kwargs)\n",
    "create_crab_spectral_model(\"magic_lp\").plot(\n",
    "    **sed_magic_ref_kwargs, label=ref_label\n",
    ")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"SED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aabde30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
